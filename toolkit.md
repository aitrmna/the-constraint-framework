---
layout: page
title: Toolkit
description: Templates and tools for applying the framework yourself
permalink: /toolkit/
---

## Apply the Framework Yourself

Everything you need to use the Constraint Framework on your own questions.

---

## Quick Reference

### The 7-Step Process

1. **Define the mystery** — What observation needs explaining?
2. **List hypotheses** — All serious competing explanations
3. **Generate predictions** — What does each hypothesis predict?
4. **Check reality** — Do predictions match observations?
5. **Score each** — Success rate × severity adjustment
6. **Compare** — Calculate advantage ratios
7. **Stack constraints** — Do multiple constraints converge?

<p><a href="{{ '/start/' | relative_url }}">Detailed walkthrough →</a></p>

---

## Prediction Quality Checklist

Good predictions are:
- [ ] **Specific** — Exact claims, not vague
- [ ] **Checkable** — Can verify yes/no
- [ ] **Falsifiable** — Can prove wrong
- [ ] **Non-circular** — Not assuming hypothesis
- [ ] **Risky** — Could actually fail

**Bad:** "Something unusual might be observed"
**Good:** "Object should accelerate >100g without sonic boom"

---

## Severity Rating Guide

### Minor Failure (-)
**10% penalty**
- Weak "might" prediction
- Non-essential to hypothesis
- Alternative explanations exist
- Example: "Might find fingerprints" → None found

### Major Failure (--)
**30% penalty**
- Strong prediction failed
- Important but not devastating
- Hard to explain away
- Example: "Should find animal reservoir within year" → None after 5 years

### Critical Failure (---)
**60% penalty**
- Absolutely required by hypothesis
- No alternative explanation
- Essentially proves hypothesis false
- Example: "Radar tracked actual objects" → Radar tracked F-16s

---

## Scoring Template

```
HYPOTHESIS: ___________________________

PREDICTIONS:
1. _______________________ → [PASS/FAIL/UNCLEAR] [Severity: -/--/---]
2. _______________________ → [PASS/FAIL/UNCLEAR] [Severity: -/--/---]
3. _______________________ → [PASS/FAIL/UNCLEAR] [Severity: -/--/---]
4. _______________________ → [PASS/FAIL/UNCLEAR] [Severity: -/--/---]
5. _______________________ → [PASS/FAIL/UNCLEAR] [Severity: -/--/---]

TOTALS:
Total predictions: ___
Confirmed: ___
Failed (minor): ___
Failed (major): ___
Failed (critical): ___
Unclear: ___

CALCULATION:
Success Rate = ___ / ___ = ___%

Severity Penalty = (__ × 0.1 + __ × 0.3 + __ × 0.6) / __ = ___%

Overall Fit = ___% × (1 - ___%) = ___%

INTERPRETATION: [Overwhelming/Strong/Moderate/Weak/Very Weak/Disproven]
```

---

## Scoring Formulas

### Success Rate
```
Success Rate = Confirmed Predictions / Total Predictions
```

### Severity Penalty
```
Severity Penalty = (Minor × 0.1 + Major × 0.3 + Critical × 0.6) / Total
```

### Overall Fit
```
Overall Fit = Success Rate × (1 - Severity Penalty)
```

### Advantage Ratio
```
Advantage Ratio = Best Hypothesis Fit / Next Best Fit
```

---

## Interpretation Scales

### Overall Fit Scale

| Score | Interpretation |
|-------|---------------|
| 90-100% | Overwhelming support |
| 70-89% | Strong support |
| 50-69% | Moderate support |
| 30-49% | Weak support |
| 10-29% | Very weak |
| 0-9% | Disproven |

### Advantage Ratio Scale

| Ratio | Meaning |
|-------|---------|
| 100:1+ | Overwhelming winner |
| 20:1 to 99:1 | Very strong winner |
| 10:1 to 19:1 | Strong winner |
| 5:1 to 9:1 | Moderate winner |
| 2:1 to 4:1 | Weak winner |
| <2:1 | Too close to call |

---

## Complete Analysis Worksheet

### Phase 1: Setup

**Mystery (one sentence):**

_________________________________________________

**Evidence types available (check all):**
- [ ] Physical evidence
- [ ] Multiple witnesses
- [ ] Documentary evidence
- [ ] Scientific data
- [ ] Statistical patterns
- [ ] Comparative cases
- [ ] Behavioral evidence

**Competing hypotheses:**

H1: _________________________________________________

H2: _________________________________________________

H3: _________________________________________________

H4: _________________________________________________

H5: _________________________________________________

---

### Phase 2: Predictions (repeat for each)

**Hypothesis:** _________________________

**Prediction 1:**
- What it predicts: ___________________________________
- Observed reality: ___________________________________
- Result: [ ] PASS [ ] FAIL [ ] UNCLEAR
- Severity if fail: [ ] Minor [ ] Major [ ] Critical

**Prediction 2:**
- What it predicts: ___________________________________
- Observed reality: ___________________________________
- Result: [ ] PASS [ ] FAIL [ ] UNCLEAR
- Severity if fail: [ ] Minor [ ] Major [ ] Critical

[Continue for all predictions...]

---

### Phase 3: Scoring

**Hypothesis 1:** _________________________

Total: _____ | Confirmed: _____ | Failed: _____

Success Rate: _____ / _____ = _____%

Minor: _____ × 0.1 = _____
Major: _____ × 0.3 = _____
Critical: _____ × 0.6 = _____
Penalty: _____ / _____ = _____%

**Overall Fit = _____ × (1 - _____) = _____%**

[Repeat for each hypothesis]

---

### Phase 4: Comparison

Best: ______________ (____%)
Second: ______________ (____%)
Ratio: _____ / _____ = _____:1

Interpretation:
[ ] Overwhelming (100:1+)
[ ] Very strong (20:1 to 99:1)
[ ] Strong (10:1 to 19:1)
[ ] Moderate (5:1 to 9:1)
[ ] Weak (2:1 to 4:1)
[ ] Too close (<2:1)

---

### Phase 5: Constraint Check

**Constraint 1:** ___________________________________ → Supports: _____

**Constraint 2:** ___________________________________ → Supports: _____

**Constraint 3:** ___________________________________ → Supports: _____

Do constraints converge? [ ] Yes [ ] No [ ] Mixed

If mixed: _______________________________________________

---

### Phase 6: Conclusion

**Most likely:** _________________________

**Confidence:**
[ ] Near certain (90%+)
[ ] High (70-90%)
[ ] Moderate (50-70%)
[ ] Low (<50%)

**Key supporting evidence:**
1. _________________________________________________
2. _________________________________________________
3. _________________________________________________

**Main uncertainty:**
_________________________________________________

**What would change conclusion:**
_________________________________________________

---

## Red Flags (Signs of Bias)

Check yourself:

- [ ] All predictions pass for preferred hypothesis → **Cherry-picking likely**
- [ ] Can't explain why ratings are major vs minor → **Arbitrary scoring**
- [ ] Conclusion matches pre-analysis belief → **Confirmation bias**
- [ ] Defensive about failed predictions → **Motivated reasoning**
- [ ] All hypotheses score similarly → **Not differentiating**

**If you check any box: Re-do the analysis with extra scrutiny.**

---

## Common Mistakes Reference

| Mistake | How to Spot | How to Fix |
|---------|------------|-----------|
| Cherry-picking | Only supporting evidence listed | Generate ALL predictions first |
| Vague predictions | "Might," "possibly," "could" | Force specificity |
| Moving goalposts | Redefining after failure | Lock in predictions before checking |
| Unfalsifiable | Nothing could prove wrong | Ask: what would disprove this? |
| False precision | "73.4% certain" | Round to brackets |
| Ignoring priors | All 50/50 starting odds | Consider base rates |
| Post-hoc fitting | Explaining after seeing data | Predict BEFORE checking |

---

## Self-Correction Protocol

**If you suspect bias:**

**1. Reverse the exercise**
- Take hypothesis you WANT to be false
- List its strongest predictions
- List weakest predictions for your preferred hypothesis
- Re-score honestly

**2. Steel-man the opposition**
- What's BEST case for alternative?
- What's WORST case for your position?
- Does conclusion survive?

**3. Time-delay test**
- Return after 24-48 hours
- Do scores still seem right?
- Would you change ratings with fresh eyes?

**4. Check with naive reader**
- Can unfamiliar person follow logic?
- Do severity ratings seem justified?
- Do they spot missed predictions?

---

## Application Templates

### Template 1: Crime/Mystery

**Hypotheses:**
- H1: Random stranger
- H2: Known associate
- H3: Family member
- H4: Accident with cover-up

**Evidence categories:**
- Physical evidence (DNA, fibers, weapons)
- Witness testimony (timeline, alibis)
- Behavior (before, during, after)
- Motive (financial, emotional)
- Opportunity (access, timeline)
- Statistical patterns (base rates)

### Template 2: Scientific Mystery

**Hypotheses:**
- H1: Natural phenomenon
- H2: Experimental artifact
- H3: Measurement error
- H4: Novel physics

**Evidence categories:**
- Reproducibility
- Mechanism
- Predictions
- Known physics consistency
- Alternative explanations

### Template 3: Historical Mystery

**Hypotheses:**
- H1: Contemporary account A
- H2: Contemporary account B
- H3: Modern theory C

**Evidence categories:**
- Primary sources
- Archaeological evidence
- Secondary sources
- Comparative history
- Physical constraints

---

## Next Steps

**Learn the methodology:**
<p><a href="{{ '/methodology/' | relative_url }}">Complete framework →</a></p>

**Understand scoring:**
<p><a href="{{ '/scoring/' | relative_url }}">Detailed scoring guide →</a></p>

**See it applied:**
<p><a href="{{ '/mysteries/' | relative_url }}">Case studies →</a></p>

---

## Remember

**The framework doesn't make you smarter. It makes your biases visible.**

Use these tools to:
- Force intellectual honesty
- Prevent cherry-picking
- Make reasoning checkable
- State confidence accurately

That's the value. Not certainty. **Intellectual honesty.**
